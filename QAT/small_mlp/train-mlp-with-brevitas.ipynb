{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Quantized MLP on the PlutoSDR Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through the process of loading the PlutoSDR dataset, declaring a Brevitas MLP model, training said model on the dataset and then exporting it to be used in FINN. The model is intentionally very small so that it can run on the PYNQ-Z2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is stored as a series of .npz files in the fullPlutoImport folder. Each file contains iq samples with labels for which channels are occupied for that file. Files are in the form _____ with ___ being the negative number of decabels the signals are bradcast at and __ being which channels are occupied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce training times this function can be used to reduce the amount of files being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_strings(lst):\n",
    "    filtered_list = [s for s in lst if not any(digit in s for digit in \"3456789\")]\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "factor is used to decide the buffer size being used with the buffer size being factor*128. This loops through each of the files and seperates the samples into lists each of the buffer length. The iq samples are combined into the same list as the MLP needs to take them all in at the same time. In order to get them in the same order as they will be received once integrated with the rest of the cognitive radio they are interleaved like [i,q,i,q,i,q,...]. The origninal data values are between 2 and -2, however the expected input will be an 8 bit integer so the values are normalised to between 127 and -128. Finally the data is split up into traing, test and validation data and put into dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "folder = \"../fullPlutoImport\"\n",
    "files = os.listdir(folder)\n",
    "\n",
    "filtered_files = filter_strings(files)\n",
    "\n",
    "factor = 2\n",
    "noFiles = len(filtered_files)\n",
    "\n",
    "arr = np.ndarray((int(7800*noFiles/factor),128*factor*2), float)\n",
    "labels = np.ndarray((int(7800*noFiles/factor),4))\n",
    "\n",
    "seed = 0\n",
    "\n",
    "i = 0;\n",
    "for idx, npz in enumerate(filtered_files):\n",
    "    \n",
    "    a = np.load(os.path.join(folder, npz))\n",
    "    \n",
    "    start_idx = (idx*int(7800/factor)) if idx <20 else (idx)*int(7800/factor)-1\n",
    "    end_idx = (1+idx)*int(7800/factor) if idx <20 else (1+idx)*int(7800/factor)-1\n",
    "           \n",
    "    reshaped_arr = a[\"samples\"].reshape(int(7800/factor), 128*factor)\n",
    "    \n",
    "    float_array = np.ndarray((int(7800/factor), 128*factor*2), float)\n",
    "    for j in range(reshaped_arr.shape[0]):\n",
    "        float_array[j] = np.ravel((reshaped_arr[j].real, reshaped_arr[j].imag),'F')\n",
    "    arr[start_idx:end_idx] = float_array\n",
    "    labels[start_idx:end_idx] = np.tile(a[\"active_channels\"],  (int(7800/factor), 1))\n",
    "\n",
    "    i+=1\n",
    "    if i >= noFiles:\n",
    "        break\n",
    "    \n",
    "normalized_array = 255 * (arr + 2) / (4) - 128\n",
    "\n",
    "# first split into train+val and test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(normalized_array, labels, test_size=0.2, random_state=seed)\n",
    "\n",
    "# then split train+val into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1, random_state=seed)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.int8), torch.tensor(y_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.int8), torch.tensor(y_test, dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.int8), torch.tensor(y_val, dtype=torch.float32))\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subset of the data is used for testing on the PYNQ-Z2. That is loaded in here so that the accuracy in hardware can be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../data\"\n",
    "files = os.listdir(folder)\n",
    "\n",
    "noFiles = len(files)\n",
    "\n",
    "arr = np.ndarray((int(7800*noFiles/factor),128*factor*2), float)\n",
    "labels = np.ndarray((int(7800*noFiles/factor),4))\n",
    "\n",
    "i = 0;\n",
    "for idx, npz in enumerate(files):\n",
    "    \n",
    "    a = np.load(os.path.join(folder, npz))\n",
    "    \n",
    "    start_idx = (idx*int(7800/factor)) if idx <20 else (idx)*int(7800/factor)-1\n",
    "    end_idx = (1+idx)*int(7800/factor) if idx <20 else (1+idx)*int(7800/factor)-1\n",
    "           \n",
    "    reshaped_arr = a[\"samples\"].reshape(int(7800/factor), 128*factor)\n",
    "\n",
    "    float_array = np.ndarray((int(7800/factor), 128*factor*2), float)\n",
    "    for j in range(reshaped_arr.shape[0]):\n",
    "        float_array[j] = np.ravel((reshaped_arr[j].real, reshaped_arr[j].imag),'F')\n",
    "    \n",
    "    arr[start_idx:end_idx] = float_array\n",
    "    labels[start_idx:end_idx] = np.tile(a[\"active_channels\"],  (int(7800/factor), 1))\n",
    "\n",
    "    i+=1\n",
    "    if i >= noFiles:\n",
    "        break\n",
    "    \n",
    "normalized_array = 255 * (arr + 2) / (4) - 128\n",
    "\n",
    "onboard_dataset = TensorDataset(torch.tensor(normalized_array, dtype=torch.int8), torch.tensor(labels, dtype=torch.float32))\n",
    "onboard_loader = DataLoader(onboard_dataset, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a PyTorch Device\n",
    "\n",
    "GPUs can significantly speed-up training of deep neural networks. We check for availability of a GPU and if so define it as target device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Target device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Quantized MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables to control the size of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128*factor*2\n",
    "hidden1 = 40\n",
    "weight_bit_width = 4\n",
    "act_bit_width = 4\n",
    "num_classes = 4  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is defined using a variety of Brevitas and PyTorch classes. Since the linear and ReLU functions are defined with Brevitas classes this means that all of the weights and activations are quantized to the previously specified values. The dropout and batchnormalization layers are from PyTorch as they cannot be quantized. It is a very small model to be able to fit on the PYNQ-Z2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): QuantLinear(\n",
       "    in_features=512, out_features=40, bias=True\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): QuantLinear(\n",
       "    in_features=40, out_features=4, bias=True\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from brevitas.nn import QuantLinear, QuantReLU\n",
    "import torch.nn as nn\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "      QuantLinear(input_size, hidden1, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden1),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden1, num_classes, bias=True, weight_bit_width=weight_bit_width)\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models outputs are not yet quantized to 0 and 1 as its confidences are used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train and Test  Methods\n",
    "The train and test methods are declared, QAT is automatically completed by Brevitas. This results in them being very similar to standard PyTorch training and testing methods. The outputs are put through a sigmoid then compared to 0.5 to convert them to binary for accuracy measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    # ensure model is in training mode\n",
    "    model.train()    \n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):        \n",
    "        inputs, target = data\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output.flatten()\n",
    "        target.flatten()\n",
    "                \n",
    "        # forward pass\n",
    "        output = model(inputs.float())\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # backward pass + run optimizer to update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of loss value\n",
    "        losses.append(loss.data.cpu().numpy()) \n",
    "           \n",
    "    return losses\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, target = data\n",
    "            inputs, target = inputs.to(device), target.to(device)\n",
    "            output_orig = model(inputs.float())\n",
    "            # run the output through sigmoid\n",
    "            output = torch.sigmoid(output_orig)  \n",
    "            # compare against a threshold of 0.5 to generate 0/1\n",
    "            pred = (output.detach().cpu().numpy() > 0.5) * 1\n",
    "            pred.flatten()\n",
    "            target.flatten()\n",
    "            target = target.cpu().float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.tolist())\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the QNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model from Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_loss_plot(losses, title=\"Training loss\", xlabel=\"Iterations\", ylabel=\"Loss\"):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss:   0%|          | 0/10 [00:00<?, ?it/s]/home/dspedia/.local/lib/python3.10/site-packages/torch/_tensor.py:1488: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1928.)\n",
      "  return super().rename(names)\n",
      "/home/dspedia/.local/lib/python3.10/site-packages/brevitas/nn/quant_linear.py:69: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:311.)\n",
      "  output_tensor = linear(x, quant_weight, quant_bias)\n",
      "Training loss = 0.509073 test accuracy = 0.542753: 100%|██████████| 10/10 [01:28<00:00,  8.87s/it]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "# loss criterion and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "running_loss = []\n",
    "running_test_acc = []\n",
    "t = trange(num_epochs, desc=\"Training loss\", leave=True)\n",
    "\n",
    "for epoch in t:\n",
    "        loss_epoch = train(model, train_loader, optimizer,criterion)\n",
    "        test_acc = test(model, test_loader)\n",
    "        t.set_description(\"Training loss = %f test accuracy = %f\" % (np.mean(loss_epoch), test_acc))\n",
    "        t.refresh() # to show immediately the update\n",
    "        running_loss.append(loss_epoch)\n",
    "        running_test_acc.append(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44682983682983685"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = test(model, onboard_loader)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5403311965811965"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = test(model, val_loader)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_loss_plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_per_epoch = [np.mean(acc_per_epoch) for acc_per_epoch in running_test_acc]\n",
    "display_loss_plot(acc_per_epoch, title=\"Test accuracy\", ylabel=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is saved for software verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Brevitas model to disk\n",
    "torch.save(model.state_dict(), \"state_dict_self-trained.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Quantization\n",
    "\n",
    "Depending on the requirements of the cognitive radio it can be better to have the model output a zero or one depending on whether the model beleives that channel is occupied. This is also more convenient for verifying the model with the deployment package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to CPU before surgery\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper class quantizes the output down to 1 bit. Brevitas uses the bipolar data type to represent this output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPForExport(\n",
       "  (pretrained): Sequential(\n",
       "    (0): QuantLinear(\n",
       "      in_features=256, out_features=40, bias=True\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (output_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (weight_quant): WeightQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClampSte()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): StatsFromParameterScaling(\n",
       "            (parameter_list_stats): _ParameterListStats(\n",
       "              (first_tracked_param): _ViewParameterWrapper(\n",
       "                (view_shape_impl): OverTensorView()\n",
       "              )\n",
       "              (stats): _Stats(\n",
       "                (stats_impl): AbsMax()\n",
       "              )\n",
       "            )\n",
       "            (stats_scaling_impl): _StatsScaling(\n",
       "              (affine_rescaling): Identity()\n",
       "              (restrict_clamp_scaling): _RestrictClampValue(\n",
       "                (clamp_min_ste): ScalarClampMinSte()\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (restrict_scaling_pre): Identity()\n",
       "              (restrict_scaling_impl): FloatRestrictValue()\n",
       "            )\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (bias_quant): BiasQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "    )\n",
       "    (1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): QuantReLU(\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (act_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "          (activation_impl): ReLU()\n",
       "          (tensor_quant): RescalingIntQuant(\n",
       "            (int_quant): IntQuant(\n",
       "              (float_to_int_impl): RoundSte()\n",
       "              (tensor_clamp_impl): TensorClamp()\n",
       "              (delay_wrapper): DelayWrapper(\n",
       "                (delay_impl): _NoDelay()\n",
       "              )\n",
       "              (input_view_impl): Identity()\n",
       "            )\n",
       "            (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "              (stats_input_view_shape_impl): OverTensorView()\n",
       "              (stats): _Stats(\n",
       "                (stats_impl): AbsPercentile()\n",
       "              )\n",
       "              (restrict_scaling_impl): FloatRestrictValue()\n",
       "              (restrict_scaling): _RestrictValue(\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (clamp_scaling): _ClampValue(\n",
       "                (clamp_min_ste): ScalarClampMinSte()\n",
       "              )\n",
       "              (restrict_inplace_preprocess): Identity()\n",
       "              (restrict_preprocess): Identity()\n",
       "            )\n",
       "            (int_scaling_impl): IntScaling()\n",
       "            (zero_point_impl): ZeroZeroPoint(\n",
       "              (zero_point): StatelessBuffer()\n",
       "            )\n",
       "            (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "              (bit_width): StatelessBuffer()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): QuantLinear(\n",
       "      in_features=40, out_features=4, bias=True\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (output_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (weight_quant): WeightQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClampSte()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): StatsFromParameterScaling(\n",
       "            (parameter_list_stats): _ParameterListStats(\n",
       "              (first_tracked_param): _ViewParameterWrapper(\n",
       "                (view_shape_impl): OverTensorView()\n",
       "              )\n",
       "              (stats): _Stats(\n",
       "                (stats_impl): AbsMax()\n",
       "              )\n",
       "            )\n",
       "            (stats_scaling_impl): _StatsScaling(\n",
       "              (affine_rescaling): Identity()\n",
       "              (restrict_clamp_scaling): _RestrictClampValue(\n",
       "                (clamp_min_ste): ScalarClampMinSte()\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (restrict_scaling_pre): Identity()\n",
       "              (restrict_scaling_impl): FloatRestrictValue()\n",
       "            )\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (bias_quant): BiasQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qnt_output): QuantIdentity(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): ClampedBinaryQuant(\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_init_module): Identity()\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (bit_width): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "          (zero_point): StatelessBuffer()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (tensor_clamp_impl): TensorClamp()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from brevitas.nn import QuantIdentity\n",
    "\n",
    "class BipolarForExport(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(BipolarForExport, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.qnt_output = QuantIdentity(\n",
    "            quant_type='binary', \n",
    "            scaling_impl_type='const',\n",
    "            bit_width=1, min_val=-1.0, max_val=1.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_original = self.pretrained(x)\n",
    "        out_final = self.qnt_output(out_original)   # output as {-1,1}     \n",
    "        return out_final\n",
    "\n",
    "\n",
    "\n",
    "model_for_export = BipolarForExport(model)\n",
    "model_for_export.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954827724358975"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_for_export, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to QONNX and Conversion to FINN-ONNX\n",
    "\n",
    "Breivtas provides functionality to export models to qonnx, the only additional information is the input data shape.\n",
    "\n",
    "FINN then needs to take the qonnx output and translate it to its \"dialect\" for it to be used with the FINN build_dataflow tool.\n",
    "\n",
    "This is repeated twice: once with the quantized output and once without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to mlp_ready.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dspedia/.local/lib/python3.10/site-packages/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 17. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "ready_model_filename = \"mlp_ready_qout.onnx\"\n",
    "input_shape = (1, 128*factor*2)\n",
    "\n",
    "# create a QuantTensor instance to mark input as bipolar during export\n",
    "input_a = np.random.randint(0, 1, size=input_shape).astype(np.float32)\n",
    "input_t = torch.from_numpy(input_a)\n",
    "\n",
    "#Move to CPU before export\n",
    "model_for_export.cpu()\n",
    "\n",
    "# Export to ONNX\n",
    "export_qonnx(\n",
    "    model_for_export, export_path=ready_model_filename, input_t=input_t\n",
    ")\n",
    "\n",
    "# clean-up\n",
    "qonnx_cleanup(ready_model_filename, out_file=ready_model_filename)\n",
    "\n",
    "outmodel = ModelWrapper(ready_model_filename)\n",
    "# Setting the input datatype explicitly because it doesn't get derived from the export function\n",
    "outmodel.set_tensor_datatype(outmodel.graph.input[0].name, DataType[\"INT8\"])\n",
    "\n",
    "outmodel = outmodel.transform(ConvertQONNXtoFINN())\n",
    "outmodel.save(ready_model_filename)\n",
    "\n",
    "print(\"Model saved to %s\" % ready_model_filename)\n",
    "\n",
    "\n",
    "ready_model_filename = \"mlp_ready.onnx\"\n",
    "model_for_export = model\n",
    "\n",
    "#Move to CPU before export\n",
    "model_for_export.cpu()\n",
    "\n",
    "# Export to ONNX\n",
    "export_qonnx(\n",
    "    model_for_export, export_path=ready_model_filename, input_t=input_t\n",
    ")\n",
    "\n",
    "# clean-up\n",
    "qonnx_cleanup(ready_model_filename, out_file=ready_model_filename)\n",
    "\n",
    "outmodel = ModelWrapper(ready_model_filename)\n",
    "# Setting the input datatype explicitly because it doesn't get derived from the export function\n",
    "outmodel.set_tensor_datatype(outmodel.graph.input[0].name, DataType[\"INT8\"])\n",
    "\n",
    "outmodel = outmodel.transform(ConvertQONNXtoFINN())\n",
    "outmodel.save(ready_model_filename)\n",
    "\n",
    "print(\"Model saved to %s\" % ready_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Exported ONNX in Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'mlp_ready.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x731671f42740>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(\"mlp_ready_qout.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
