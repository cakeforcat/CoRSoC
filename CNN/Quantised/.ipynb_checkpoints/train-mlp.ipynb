{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Quantized MLP on UNSW-NB15 with Brevitas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Live FINN tutorial:** We recommend clicking **Cell -> Run All** when you start reading this notebook for \"latency hiding\".</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to create, train and export a quantized Multi Layer Perceptron (MLP) with quantized weights and activations with [Brevitas](https://github.com/Xilinx/brevitas).\n",
    "Specifically, the task at hand will be to label network packets as normal or suspicious (e.g. originating from an attacker, virus, malware or otherwise) by training on a quantized variant of the UNSW-NB15 dataset. \n",
    "\n",
    "**You won't need a GPU to train the neural net.** This MLP will be small enough to train on a modern x86 CPU, so no GPU is required to follow this tutorial  Alternatively, we provide pre-trained parameters for the MLP if you want to skip the training entirely.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick introduction to the task and the dataset\n",
    "\n",
    "*The task:* The goal of [*network intrusion detection*](https://ieeexplore.ieee.org/abstract/document/283931) is to identify, preferably in real time, unauthorized use, misuse, and abuse of computer systems by both system insiders and external penetrators. This may be achieved by a mix of techniques, and machine-learning (ML) based techniques are increasing in popularity. \n",
    "\n",
    "*The dataset:* Several datasets are available for use in ML-based methods for intrusion detection.\n",
    "The **UNSW-NB15** is one such dataset created by the Australian Centre for Cyber Security (ACCS) to provide a comprehensive network based data set which can reflect modern network traffic scenarios. You can find more details about the dataset on [its homepage](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/).\n",
    "\n",
    "*Performance considerations:* FPGAs are commonly used for implementing high-performance packet processing systems that still provide a degree of programmability. To avoid introducing bottlenecks on the network, the DNN implementation must be capable of detecting malicious ones at line rate, which can be millions of packets per second, and is expected to increase further as next-generation networking solutions provide increased\n",
    "throughput. This is a good reason to consider FPGA acceleration for this particular use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "-------------\n",
    "\n",
    "* [Load the UNSW_NB15 Dataset](#load_dataset) \n",
    "* [Define a PyTorch Device](#define_pytorch_device)\n",
    "* [Define the Quantized MLP Model](#define_quantized_mlp)\n",
    "* [Define Train and Test  Methods](#train_test)\n",
    "    * [(Option 1) Train the Model from Scratch](#train_scratch)\n",
    "    * [(Option 2) Load Pre-Trained Parameters](#load_pretrained)\n",
    "* [Network Surgery Before Export](#network_surgery)\n",
    "* [Export to QONNX and Conversion to FINN-ONNX](#export_qonnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import onnx\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_dir = \"\"#os.environ['FINN_ROOT'] + \"/notebooks/end2end_example/cybersecurity\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is important -- always import onnx before torch**. This is a workaround for a [known bug](https://github.com/onnx/onnx/issues/2394)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the UNSW_NB15 Dataset <a id='load_dataset'></a>\n",
    "\n",
    "### Dataset Quantization <a id='dataset_qnt'></a>\n",
    "\n",
    "The goal of this notebook is to train a Quantized Neural Network (QNN) to be later deployed as an FPGA accelerator generated by the FINN compiler. Although we can choose a variety of different precisions for the input, [Murovic and Trost](https://ev.fe.uni-lj.si/1-2-2019/Murovic.pdf) have previously shown we can actually binarize the inputs and still get good (90%+) accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a binarized representation for the dataset by following the procedure defined by Murovic and Trost, which we repeat briefly here:\n",
    "\n",
    "* Original features have different formats ranging from integers, floating numbers to strings.\n",
    "* Integers, which for example represent a packet lifetime, are binarized with as many bits as to include the maximum value. \n",
    "* Another case is with features formatted as strings (protocols), which are binarized by simply counting the number of all different strings for each feature and coding them in the appropriate number of bits.\n",
    "* Floating-point numbers are reformatted into fixed-point representation.\n",
    "* In the end, each sample is transformed into a 593-bit wide binary vector. \n",
    "* All vectors are labeled as bad (0) or normal (1)\n",
    "\n",
    "Following Murovic and Trost's open-source implementation provided as a Matlab script [here](https://github.com/TadejMurovic/BNN_Deployment/blob/master/cybersecurity_dataset_unswb15.m), we've created a [Python version](dataloader_quantized.py).\n",
    "\n",
    "<font color=\"red\">**Live FINN tutorial:** Downloading the original dataset and quantizing it can take some time, so we provide a download link to the pre-quantized version for your convenience. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the binarized numpy arrays from the .npz archive and wrap them as a PyTorch `TensorDataset` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_array(arr):\n",
    "\n",
    "  # find the minimum and maximum values in the array.\n",
    "  min_val = np.min(arr)\n",
    "  max_val = np.max(arr)\n",
    "\n",
    "  normalized_arr = 2 * (arr - min_val) / (max_val - min_val) - 1\n",
    "\n",
    "  return normalized_arr\n",
    "\n",
    "\n",
    "def filter_strings(lst):\n",
    "    filtered_list = [s for s in lst if not any(digit in s for digit in \"23456789\")]\n",
    "    return filtered_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array min: -1.9402850002906638, max: 1.9402850002906638\n",
      "Normalized array min: -1.0, max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from torch.utils.data import TensorDataset\n",
    "\n",
    "# def get_preqnt_dataset(data_dir: str, train: bool):\n",
    "#     unsw_nb15_data = np.load(data_dir + \"/unsw_nb15_binarized.npz\")\n",
    "#     if train:\n",
    "#         partition = \"train\"\n",
    "#     else:\n",
    "#         partition = \"test\"\n",
    "#     part_data = unsw_nb15_data[partition].astype(np.float32)\n",
    "#     part_data = torch.from_numpy(part_data)\n",
    "#     part_data_in = part_data[:, :-1]\n",
    "#     part_data_out = part_data[:, -1]\n",
    "#     return TensorDataset(part_data_in, part_data_out)\n",
    "\n",
    "# train_quantized_dataset = get_preqnt_dataset(\".\", True)\n",
    "# test_quantized_dataset = get_preqnt_dataset(\".\", False)\n",
    "\n",
    "# print(\"Samples in each set: train = %d, test = %s\" % (len(train_quantized_dataset), len(test_quantized_dataset))) \n",
    "# print(\"Shape of one input sample: \" +  str(train_quantized_dataset[0][0].shape))\n",
    "\n",
    "import numpy as np\n",
    "import os as os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "#from torchsummary import summary\n",
    "import brevitas.nn as qnn\n",
    "from torchmetrics.classification import MultilabelAccuracy, MultilabelPrecision, MultilabelRecall, MultilabelF1Score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder = \"../PlutoImport\"\n",
    "files = os.listdir(folder)\n",
    "\n",
    "filtered_files = filter_strings(files)\n",
    "\n",
    "factor = 8\n",
    "noFiles = len(filtered_files)\n",
    "\n",
    "arr = np.ndarray((int(7800*noFiles/factor),2*128*factor), float)\n",
    "labels = np.ndarray((int(7800*noFiles/factor),4))\n",
    "\n",
    "seed = 42\n",
    "\n",
    "i = 0;\n",
    "for idx, npz in enumerate(filtered_files):\n",
    "    \n",
    "    a = np.load(os.path.join(folder, npz))\n",
    "    \n",
    "    start_idx = (idx*int(7800/factor)) if idx <20 else (idx)*int(7800/factor)-1\n",
    "    end_idx = (1+idx)*int(7800/factor) if idx <20 else (1+idx)*int(7800/factor)-1\n",
    "    \n",
    "    # print(f\"start index: {start_idx}, end index {end_idx}, activate channels: {a['active_channels']}\")\n",
    "       \n",
    "    reshaped_arr = a[\"samples\"].reshape(int(7800/factor), 128*factor)\n",
    "    \n",
    "    float_array = np.stack((reshaped_arr.real, reshaped_arr.imag), axis=1) \n",
    "\n",
    "    float_array = float_array.reshape(int(7800/factor), 2*128*factor)\n",
    "\n",
    "    arr[start_idx:end_idx] = float_array\n",
    "    labels[start_idx:end_idx] = np.tile(a[\"active_channels\"],  (int(7800/factor), 1))\n",
    "\n",
    "    i+=1\n",
    "    if i >= noFiles:\n",
    "        break\n",
    "    \n",
    "normalized_array = normalize_array(arr)\n",
    "labels = labels[:-1]\n",
    "\n",
    "\n",
    "print(f\"Original array min: {np.min(arr)}, max: {np.max(arr)}\")\n",
    "print(f\"Normalized array min: {np.min(normalized_array)}, max: {np.max(normalized_array)}\")\n",
    "\n",
    "arr = normalized_array[:-1]\n",
    "\n",
    "# first split into train+val and test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(arr, labels, test_size=0.2, random_state=seed)\n",
    "\n",
    "# then split train+val into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=seed)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataLoader\n",
    "\n",
    "Following either option, we now have access to the quantized dataset. We will wrap the dataset in a PyTorch `DataLoader` for easier access in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for 1 batch: torch.Size([256, 2048])\n",
      "Label shape for 1 batch: torch.Size([256, 4])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for x,y in train_loader:\n",
    "    print(\"Input shape for 1 batch: \" + str(x.shape))\n",
    "    print(\"Label shape for 1 batch: \" + str(y.shape))\n",
    "    count += 1\n",
    "    if count == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2500,  0.2500,  0.2500,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.2500, -0.2500,  0.2500,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.2500,  ...,  0.0000, -0.2500,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.2500,  0.0000,  ..., -0.2500,  0.2500,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.2500,  ...,  0.2500,  0.2500,  0.0000],\n",
      "        [-0.2500, -0.2500,  0.2500,  ..., -0.2500, -0.2500,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset.tensors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a PyTorch Device <a id='define_pytorch_device'></a> \n",
    "\n",
    "GPUs can significantly speed-up training of deep neural networks. We check for availability of a GPU and if so define it as target device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Target device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Quantized MLP Model <a id='define_quantized_mlp'></a>\n",
    "\n",
    "We'll now define an MLP model that will be trained to perform inference with quantized weights and activations.\n",
    "For this, we'll use the quantization-aware training (QAT) capabilities offered by [Brevitas](https://github.com/Xilinx/brevitas).\n",
    "\n",
    "Our MLP will have four fully-connected (FC) layers in total: three hidden layers with 64 neurons, and a final output layer with a single output, all using 2-bit weights. We'll use 2-bit quantized ReLU activation functions, and apply batch normalization between each FC layer and its activation.\n",
    "\n",
    "In case you'd like to experiment with different quantization settings or topology parameters, we'll define all these topology settings as variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2048      \n",
    "hidden1 = 64      \n",
    "hidden2 = 64\n",
    "hidden3 = 64\n",
    "weight_bit_width = 2\n",
    "act_bit_width = 2\n",
    "num_classes = 4    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our MLP using the layer primitives provided by Brevitas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): QuantHardTanh(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_init_module): Identity()\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): QuantLinear(\n",
       "    in_features=2048, out_features=64, bias=True\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): QuantLinear(\n",
       "    in_features=64, out_features=64, bias=True\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.5, inplace=False)\n",
       "  (8): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (9): QuantLinear(\n",
       "    in_features=64, out_features=64, bias=True\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Dropout(p=0.5, inplace=False)\n",
       "  (12): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (13): QuantLinear(\n",
       "    in_features=64, out_features=4, bias=True\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from brevitas.nn import QuantLinear, QuantReLU, QuantIdentity\n",
    "import brevitas.quant.fixed_point\n",
    "import torch.nn as nn\n",
    "from brevitas.inject.enum import ScalingImplType\n",
    "from brevitas.inject.defaults import Int8ActPerTensorFloatMinMaxInit\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class InputQuantizer(Int8ActPerTensorFloatMinMaxInit):\n",
    "    bit_width = act_bit_width\n",
    "    min_val = -2.0\n",
    "    max_val = 2.0\n",
    "    scaling_impl_type = ScalingImplType.CONST # Fix the quantization range to [min_val, max_val]\n",
    "\n",
    "model = nn.Sequential(\n",
    "      qnn.QuantHardTanh(act_quant=InputQuantizer),\n",
    "      QuantLinear(input_size, hidden1, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden1),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden1, hidden2, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden2),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden2, hidden3, bias=True, weight_bit_width=weight_bit_width),\n",
    "      nn.BatchNorm1d(hidden3),\n",
    "      nn.Dropout(0.5),\n",
    "      QuantReLU(bit_width=act_bit_width),\n",
    "      QuantLinear(hidden3, num_classes, bias=True, weight_bit_width=weight_bit_width)\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): QuantHardTanh(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): Identity()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_init_module): Identity()\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): QuantConv1d(\n",
       "    2, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): QuantConv1d(\n",
       "    64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): QuantConv1d(\n",
       "    64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (12): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (13): QuantConv1d(\n",
       "    64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (14): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (16): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): QuantConv1d(\n",
       "    64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (18): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (20): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (21): QuantConv1d(\n",
       "    64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (22): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (23): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (24): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (25): QuantConv1d(\n",
       "    64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (26): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (27): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (28): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (29): Flatten(start_dim=1, end_dim=-1)\n",
       "  (30): QuantLinear(\n",
       "    in_features=512, out_features=128, bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (31): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (32): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (33): QuantLinear(\n",
       "    in_features=128, out_features=128, bias=False\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (34): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (35): QuantReLU(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): ReLU()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClamp()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "            (stats_input_view_shape_impl): OverTensorView()\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsPercentile()\n",
       "            )\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "            (restrict_scaling): _RestrictValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (clamp_scaling): _ClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "            )\n",
       "            (restrict_inplace_preprocess): Identity()\n",
       "            (restrict_preprocess): Identity()\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (36): QuantLinear(\n",
       "    in_features=128, out_features=4, bias=True\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): RescalingIntQuant(\n",
       "        (int_quant): IntQuant(\n",
       "          (float_to_int_impl): RoundSte()\n",
       "          (tensor_clamp_impl): TensorClampSte()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (input_view_impl): Identity()\n",
       "        )\n",
       "        (scaling_impl): StatsFromParameterScaling(\n",
       "          (parameter_list_stats): _ParameterListStats(\n",
       "            (first_tracked_param): _ViewParameterWrapper(\n",
       "              (view_shape_impl): OverTensorView()\n",
       "            )\n",
       "            (stats): _Stats(\n",
       "              (stats_impl): AbsMax()\n",
       "            )\n",
       "          )\n",
       "          (stats_scaling_impl): _StatsScaling(\n",
       "            (affine_rescaling): Identity()\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_scaling_pre): Identity()\n",
       "            (restrict_scaling_impl): FloatRestrictValue()\n",
       "          )\n",
       "        )\n",
       "        (int_scaling_impl): IntScaling()\n",
       "        (zero_point_impl): ZeroZeroPoint(\n",
       "          (zero_point): StatelessBuffer()\n",
       "        )\n",
       "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.quant import IntBias\n",
    "from brevitas.inject.enum import ScalingImplType\n",
    "from brevitas.inject.defaults import Int8ActPerTensorFloatMinMaxInit\n",
    "\n",
    "# Adjustable hyperparameters\n",
    "input_bits = 8\n",
    "a_bits = 8\n",
    "w_bits = 8\n",
    "filters_conv = 64\n",
    "filters_dense = 128\n",
    "batch_size = 1024\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "class InputQuantizer(Int8ActPerTensorFloatMinMaxInit):\n",
    "    bit_width = input_bits\n",
    "    min_val = -2.0\n",
    "    max_val = 2.0\n",
    "    scaling_impl_type = ScalingImplType.CONST # Fix the quantization range to [min_val, max_val]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # Input quantization layer\n",
    "    qnn.QuantHardTanh(act_quant=InputQuantizer),\n",
    "\n",
    "    qnn.QuantConv1d(2, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits,bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "\n",
    "    qnn.QuantLinear(filters_conv*8, filters_dense, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_dense),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "\n",
    "    qnn.QuantLinear(filters_dense, filters_dense, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_dense),\n",
    "    qnn.QuantReLU(bit_width=a_bits, return_quant_tensor=True),\n",
    "\n",
    "    qnn.QuantLinear(filters_dense, 4, weight_bit_width=w_bits, bias=True),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the MLP's output is not yet quantized. Even though we want the final output of our MLP to be a binary (0/1) value indicating the classification, we've only defined a single-neuron FC layer as the output. While training the network we'll pass that output through a sigmoid function as part of the loss criterion, which [gives better numerical stability](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html). Later on, after we're done training the network, we'll add a quantization node at the end before we export it to FINN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train and Test  Methods  <a id='train_test'></a>\n",
    "The train and test methods will use a `DataLoader`, which feeds the model with a new predefined batch of training data in each iteration, until the entire training data is fed to the model. Each repetition of this process is called an `epoch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0\n"
     ]
    }
   ],
   "source": [
    "# Select which GPU to use (if available)\n",
    "gpu = 0\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.device(gpu)\n",
    "    print(\"Using GPU %d\" % gpu)\n",
    "else:\n",
    "    gpu = None\n",
    "    print(\"Using CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    # ensure model is in training mode\n",
    "    model.train()    \n",
    "\n",
    "    for (inputs, target) in tqdm(train_loader, desc=\"Batches\", leave=False):   \n",
    "        if gpu is not None:\n",
    "            inputs = inputs.cuda()\n",
    "            target = target.cuda()\n",
    "                \n",
    "        # forward pass\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # backward pass + run optimizer to update weights\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of loss value\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "           \n",
    "    return losses\n",
    "\n",
    "def test(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for (inputs, target) in test_loader:\n",
    "            if gpu is not None:\n",
    "                inputs = inputs.cuda()\n",
    "                target = target.cuda()\n",
    "            output = model(inputs)\n",
    "\n",
    "            pred = (output.detach().cpu().numpy() > 0.5) * 1\n",
    "            target = target.cpu().float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred)\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def display_loss_plot(losses, title=\"Training loss\", xlabel=\"Iterations\", ylabel=\"Loss\"):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68316520dd2b4ef8936671ba8e7c71f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d0b650f8b944dba7e4195924bcbfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training loss = 0.000000, test accuracy = 1.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1434ab06da34caf90fa6e5ba200e795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training loss = 0.000000, test accuracy = 1.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc57ee70459f4535aaf28e65867d9d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training loss = 0.000000, test accuracy = 1.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c145e72333457a9b217e5d8ae8c835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Training loss = 0.000000, test accuracy = 1.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918741a7bca9478683d8a3b499415486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Training loss = 0.000000, test accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "num_epochs = 5\n",
    "\n",
    "data_loader_train = train_loader\n",
    "data_loader_test = test_loader\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# loss criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "\n",
    "running_loss = []\n",
    "running_test_acc = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "        loss_epoch = train(model, data_loader_train, optimizer, criterion)\n",
    "        test_acc = test(model, data_loader_test)\n",
    "        print(\"Epoch %d: Training loss = %f, test accuracy = %f\" % (epoch, np.mean(loss_epoch), test_acc))\n",
    "        running_loss.append(loss_epoch)\n",
    "        running_test_acc.append(test_acc)\n",
    "        lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "max_pool1d() Invalid computed output size: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 107\u001b[0m\n\u001b[1;32m    104\u001b[0m        \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_f1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_precision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_recall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'''\u001b[39m)\n\u001b[1;32m    106\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 107\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 65\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, epoch)\u001b[0m\n\u001b[1;32m     62\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust shape for Conv1d\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Simulated target tensor (batch_size=1, single label)       \u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m  \u001b[38;5;66;03m# Ensure correct shape\u001b[39;00m\n\u001b[1;32m     71\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Converts shape from [batch_size, 1] to [batch_size]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/pooling.py:134\u001b[0m, in \u001b[0;36mMaxPool1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_jit_internal.py:624\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:740\u001b[0m, in \u001b[0;36m_max_pool1d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    739\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: max_pool1d() Invalid computed output size: 0"
     ]
    }
   ],
   "source": [
    "# def train(model, train_loader, optimizer, criterion):\n",
    "#     losses = []\n",
    "#     # ensure model is in training mode\n",
    "#     model.train()    \n",
    "    \n",
    "#     for i, data in enumerate(train_loader, 0):        \n",
    "#         inputs, target = data\n",
    "#         inputs, target = inputs.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()   \n",
    "                \n",
    "#         # forward pass\n",
    "#         output = model(inputs.float())\n",
    "#         loss = criterion(output, target.unsqueeze(1))\n",
    "        \n",
    "#         # backward pass + run optimizer to update weights\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # keep track of loss value\n",
    "#         losses.append(loss.data.cpu().numpy()) \n",
    "           \n",
    "#     return losses\n",
    "\n",
    "# Initialize metrics\n",
    "from torchmetrics.classification import MultilabelAccuracy, MultilabelPrecision, MultilabelRecall, MultilabelF1Score\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "accuracy_func = MultilabelAccuracy(num_labels=4).to(device)\n",
    "precision_func = MultilabelPrecision(num_labels=4).to(device)\n",
    "recall_func = MultilabelRecall(num_labels=4).to(device)\n",
    "f1_score_func = MultilabelF1Score(num_labels=4).to(device)\n",
    "\n",
    "\n",
    "def train(model, train_loader, epoch=5):\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = epoch\n",
    "    best_accuracy = 0\n",
    "    patience = 20\n",
    "    counter = 0\n",
    "    \n",
    "    history_df = pd.DataFrame(columns=['epoch', 'accuracy','loss','precision', 'recall', 'F1-Score'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "       model.train()\n",
    "       running_loss = 0.0\n",
    "       correct = 0\n",
    "       total = 0\n",
    "       no_loops =0\n",
    "       precision =  0.0\n",
    "       recall = 0.0\n",
    "       f1 = 0.0\n",
    "       \n",
    "       \n",
    "\n",
    "       for inputs, labels in train_loader:\n",
    "           \n",
    "           inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "           optimizer.zero_grad()\n",
    "           outputs = model(inputs)  # Adjust shape for Conv1d\n",
    "           # Simulated target tensor (batch_size=1, single label)       \n",
    "           \n",
    "           \n",
    "           \n",
    "            # Ensure correct shape\n",
    "           outputs = outputs.squeeze(1)  # Converts shape from [batch_size, 1] to [batch_size]\n",
    "           \n",
    "            # Compute loss\n",
    "           loss = criterion(outputs, labels)\n",
    "           loss.backward()\n",
    "           optimizer.step()\n",
    "           running_loss += loss.item()\n",
    "\n",
    "           # Calculate metrics \n",
    "           predictions = torch.sigmoid(outputs) > 0.5\n",
    "           \n",
    "           predictions = predictions.int()\n",
    "           \n",
    "           correct += accuracy_func(predictions, labels)\n",
    "           precision += precision_func(predictions, labels)\n",
    "           recall += recall_func(predictions, labels)\n",
    "           f1 += f1_score_func(predictions, labels)\n",
    "           \n",
    "           no_loops += 1 # to normalise preccision recall\n",
    "           total += labels.size(0) # total no of samples \n",
    "\n",
    "       \n",
    "\n",
    "       epoch_loss = running_loss / len(train_loader)\n",
    "       epoch_accuracy = correct /no_loops\n",
    "       epoch_recall = recall/no_loops\n",
    "       epoch_precision = precision/no_loops\n",
    "       epoch_f1 = f1/no_loops\n",
    "       \n",
    "       \n",
    "       \n",
    "       \n",
    "\n",
    "       print(f'''Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.8f}, Accuracy: {epoch_accuracy:.8f}, F1-Score: {epoch_f1}, Precision: {epoch_precision}, Recall: {epoch_recall}''')\n",
    "\n",
    "model.to(device)\n",
    "train(model, train_loader, epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_Loss: 0.50842524, val_Accuracy: 0.91923076, val_F1-Score: 0.0, Precision: 0.0, Recall: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test(model, test_loader):    \n",
    "\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_no_loops = 0\n",
    "    val_precision =  0.0\n",
    "    val_recall = 0.0\n",
    "    val_f1 = 0.0\n",
    "       \n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "           \n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(inputs.transpose(2,1))  # Adjust shape for Conv1d\n",
    "          # Simulated target tensor (batch_size=1, single label)\n",
    "       \n",
    "           # Ensure correct shape\n",
    "          outputs = outputs.squeeze(1)  # Converts shape from [batch_size, 1] to [batch_size]\n",
    "           \n",
    "           # Compute loss\n",
    "          loss = criterion(outputs, labels)\n",
    "          val_running_loss += loss.item()\n",
    "\n",
    "          # Calculate metrics \n",
    "          predictions = torch.sigmoid(outputs) > 0.5\n",
    "          \n",
    "          predictions = predictions.int()\n",
    "\n",
    "        \n",
    "        # Compute metrics\n",
    "          val_correct += accuracy_func(predictions, labels)\n",
    "          val_precision += precision_func(predictions, labels)\n",
    "          val_recall += recall_func(predictions, labels)\n",
    "          val_f1 += f1_score_func(predictions, labels)\n",
    "\n",
    "          \n",
    "          val_no_loops += 1 # to normalise preccision recall\n",
    "          val_total += labels.size(0) # total no of samples \n",
    "        \n",
    "    val_epoch_loss = val_running_loss / len(test_loader)\n",
    "    val_epoch_accuracy = val_correct / val_no_loops\n",
    "    val_epoch_recall = val_recall/val_no_loops\n",
    "    val_epoch_precision = val_precision/val_no_loops\n",
    "    val_epoch_f1 = val_f1/val_no_loops\n",
    "\n",
    "    print(f'''val_Loss: {val_epoch_loss:.8}, val_Accuracy: {val_epoch_accuracy:.8}, val_F1-Score: {val_epoch_f1}, Precision: {val_epoch_precision}, Recall: {val_epoch_recall}\\n\\n''')\n",
    "\n",
    "\n",
    "    # # ensure model is in eval mode\n",
    "    # model.eval() \n",
    "    # y_true = []\n",
    "    # y_pred = []\n",
    "   \n",
    "    # with torch.no_grad():\n",
    "    #     for data in test_loader:\n",
    "    #         inputs, target = data\n",
    "    #         inputs, target = inputs.to(device), target.to(device)\n",
    "    #         output_orig = model(inputs.float())\n",
    "    #         # run the output through sigmoid\n",
    "    #         output = torch.sigmoid(output_orig)  \n",
    "    #         # compare against a threshold of 0.5 to generate 0/1\n",
    "    #         pred = (output.detach().cpu().numpy() > 0.5) * 1\n",
    "    #         target = target.cpu().float()\n",
    "    #         y_true.extend(target.tolist()) \n",
    "    #         y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "    # return accuracy_score(y_true, y_pred)\n",
    "\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    # ensure model is in training mode\n",
    "    model.train()    \n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):        \n",
    "        inputs, target = data\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        optimizer.zero_grad()   \n",
    "                \n",
    "        # forward pass\n",
    "        output = model(inputs.float())\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # backward pass + run optimizer to update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of loss value\n",
    "        losses.append(loss.data.cpu().numpy()) \n",
    "           \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, target = data\n",
    "            inputs, target = inputs.to(device), target.to(device)\n",
    "            output_orig = model(inputs.float())\n",
    "            # run the output through sigmoid\n",
    "            output = torch.sigmoid(output_orig)  \n",
    "            # compare against a threshold of 0.5 to generate 0/1\n",
    "            pred = (output.detach().cpu().numpy() > 0.5) * 1\n",
    "            target = target.cpu().float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred)\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the QNN <a id=\"train_qnn\"></a>\n",
    "\n",
    "We provide two options for training below: you can opt for training the model from scratch (slower) or use a pre-trained model (faster). The first option will give more insight into how the training process works, while the second option will likely give better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Option 1, slower) Train the Model from Scratch <a id=\"train_scratch\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training our MLP we need to define some hyperparameters. Moreover, in order to monitor the loss function evolution over epochs, we need to define a method for it. As mentioned earlier, we'll use a loss criterion which applies a sigmoid function during the training phase (`BCEWithLogitsLoss`). For the testing phase, we're manually computing the sigmoid and thresholding at 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.001 \n",
    "\n",
    "def display_loss_plot(losses, title=\"Training loss\", xlabel=\"Iterations\", ylabel=\"Loss\"):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss criterion and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss = 0.344857 test accuracy = 0.020513: 100%|| 10/10 [00:00<00:00, 32.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "running_loss = []\n",
    "running_test_acc = []\n",
    "t = trange(num_epochs, desc=\"Training loss\", leave=True)\n",
    "\n",
    "for epoch in t:\n",
    "        loss_epoch = train(model, train_loader, optimizer,criterion)\n",
    "        test_acc = test(model, test_loader)\n",
    "        t.set_description(\"Training loss = %f test accuracy = %f\" % (np.mean(loss_epoch), test_acc))\n",
    "        t.refresh() # to show immediately the update           \n",
    "        running_loss.append(loss_epoch)\n",
    "        running_test_acc.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_loss_plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_per_epoch = [np.mean(acc_per_epoch) for acc_per_epoch in running_test_acc]\n",
    "display_loss_plot(acc_per_epoch, title=\"Test accuracy\", ylabel=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Brevitas model to disk\n",
    "torch.save(model.state_dict(), \"state_dict_self-trained.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Surgery Before Export <a id=\"network_surgery\"></a>\n",
    "\n",
    "Sometimes, it's desirable to make some changes to our trained network prior to export (this is known in general as \"network surgery\"). This depends on the model and is not generally necessary, but in this case we want to make a couple of changes to get better results with FINN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to CPU before surgery\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by padding the input. Our input vectors are 593-bit, which will make folding (parallelization) for the first layer a bit tricky since 593 is a prime number. So we'll pad the weight matrix of the first layer with seven 0-valued columns to work with an input size of 600 instead. When using the modified network we'll similarly provide inputs padded to 600 bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll modify the expected input/output ranges. In FINN, we prefer to work with bipolar {-1, +1} instead of binary {0, 1} values. To achieve this, we'll create a \"wrapper\" model that handles the pre/postprocessing as follows:\n",
    "\n",
    "* on the input side, we'll pre-process by (x + 1) / 2 in order to map incoming {-1, +1} inputs to {0, 1} ones which the trained network is used to. Since we're just multiplying/adding a scalar, these operations can be [*streamlined*](https://finn.readthedocs.io/en/latest/nw_prep.html#streamlining-transformations) by FINN and implemented with no extra cost.\n",
    "\n",
    "* on the output side, we'll add a binary quantizer which maps everthing below 0 to -1 and everything above 0 to +1. This is essentially the same behavior as the sigmoid we used earlier, except the outputs are bipolar instead of binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPForExport(\n",
       "  (pretrained): Sequential(\n",
       "    (0): QuantHardTanh(\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (act_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "          (activation_impl): Identity()\n",
       "          (tensor_quant): RescalingIntQuant(\n",
       "            (int_quant): IntQuant(\n",
       "              (float_to_int_impl): RoundSte()\n",
       "              (tensor_clamp_impl): TensorClamp()\n",
       "              (delay_wrapper): DelayWrapper(\n",
       "                (delay_impl): _NoDelay()\n",
       "              )\n",
       "              (input_view_impl): Identity()\n",
       "            )\n",
       "            (scaling_impl): ConstScaling(\n",
       "              (restrict_clamp_scaling): _RestrictClampValue(\n",
       "                (clamp_min_ste): Identity()\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (restrict_init_module): Identity()\n",
       "              (value): StatelessBuffer()\n",
       "            )\n",
       "            (int_scaling_impl): IntScaling()\n",
       "            (zero_point_impl): ZeroZeroPoint(\n",
       "              (zero_point): StatelessBuffer()\n",
       "            )\n",
       "            (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "              (bit_width): StatelessBuffer()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): QuantLinear(\n",
       "      in_features=2048, out_features=64, bias=True\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (output_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (weight_quant): WeightQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClampSte()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): StatsFromParameterScaling(\n",
       "            (parameter_list_stats): _ParameterListStats(\n",
       "              (first_tracked_param): _ViewParameterWrapper(\n",
       "                (view_shape_impl): OverTensorView()\n",
       "              )\n",
       "              (stats): _Stats(\n",
       "                (stats_impl): AbsMax()\n",
       "              )\n",
       "            )\n",
       "            (stats_scaling_impl): _StatsScaling(\n",
       "              (affine_rescaling): Identity()\n",
       "              (restrict_clamp_scaling): _RestrictClampValue(\n",
       "                (clamp_min_ste): ScalarClampMinSte()\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (restrict_scaling_pre): Identity()\n",
       "              (restrict_scaling_impl): FloatRestrictValue()\n",
       "            )\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (bias_quant): BiasQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "    )\n",
       "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): QuantReLU(\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (act_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "          (activation_impl): ReLU()\n",
       "          (tensor_quant): RescalingIntQuant(\n",
       "            (int_quant): IntQuant(\n",
       "              (float_to_int_impl): RoundSte()\n",
       "              (tensor_clamp_impl): TensorClamp()\n",
       "              (delay_wrapper): DelayWrapper(\n",
       "                (delay_impl): _NoDelay()\n",
       "              )\n",
       "              (input_view_impl): Identity()\n",
       "            )\n",
       "            (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "              (stats_input_view_shape_impl): OverTensorView()\n",
       "              (stats): _Stats(\n",
       "                (stats_impl): AbsPercentile()\n",
       "              )\n",
       "              (restrict_scaling_impl): FloatRestrictValue()\n",
       "              (restrict_scaling): _RestrictValue(\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (clamp_scaling): _ClampValue(\n",
       "                (clamp_min_ste): ScalarClampMinSte()\n",
       "              )\n",
       "              (restrict_inplace_preprocess): Identity()\n",
       "              (restrict_preprocess): Identity()\n",
       "            )\n",
       "            (int_scaling_impl): IntScaling()\n",
       "            (zero_point_impl): ZeroZeroPoint(\n",
       "              (zero_point): StatelessBuffer()\n",
       "            )\n",
       "            (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "              (bit_width): StatelessBuffer()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): QuantLinear(\n",
       "      in_features=64, out_features=64, bias=True\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (output_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (weight_quant): WeightQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClampSte()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): StatsFromParameterScaling(\n",
       "            (parameter_list_stats): _ParameterListStats(\n",
       "              (first_tracked_param): _ViewParameterWrapper(\n",
       "                (view_shape_impl): OverTensorView()\n",
       "              )\n",
       "              (stats): _Stats(\n",
       "                (stats_impl): AbsMax()\n",
       "              )\n",
       "            )\n",
       "            (stats_scaling_impl): _StatsScaling(\n",
       "              (affine_rescaling): Identity()\n",
       "              (restrict_clamp_scaling): _RestrictClampValue(\n",
       "                (clamp_min_ste): ScalarClampMinSte()\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (restrict_scaling_pre): Identity()\n",
       "              (restrict_scaling_impl): FloatRestrictValue()\n",
       "            )\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (bias_quant): BiasQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "    )\n",
       "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): QuantReLU(\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (act_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "          (activation_impl): ReLU()\n",
       "          (tensor_quant): RescalingIntQuant(\n",
       "            (int_quant): IntQuant(\n",
       "              (float_to_int_impl): RoundSte()\n",
       "              (tensor_clamp_impl): TensorClamp()\n",
       "              (delay_wrapper): DelayWrapper(\n",
       "                (delay_impl): _NoDelay()\n",
       "              )\n",
       "              (input_view_impl): Identity()\n",
       "            )\n",
       "            (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "              (stats_input_view_shape_impl): OverTensorView()\n",
       "              (stats): _Stats(\n",
       "                (stats_impl): AbsPercentile()\n",
       "              )\n",
       "              (restrict_scaling_impl): FloatRestrictValue()\n",
       "              (restrict_scaling): _RestrictValue(\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (clamp_scaling): _ClampValue(\n",
       "                (clamp_min_ste): ScalarClampMinSte()\n",
       "              )\n",
       "              (restrict_inplace_preprocess): Identity()\n",
       "              (restrict_preprocess): Identity()\n",
       "            )\n",
       "            (int_scaling_impl): IntScaling()\n",
       "            (zero_point_impl): ZeroZeroPoint(\n",
       "              (zero_point): StatelessBuffer()\n",
       "            )\n",
       "            (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "              (bit_width): StatelessBuffer()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): QuantLinear(\n",
       "      in_features=64, out_features=64, bias=True\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (output_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (weight_quant): WeightQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClampSte()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): StatsFromParameterScaling(\n",
       "            (parameter_list_stats): _ParameterListStats(\n",
       "              (first_tracked_param): _ViewParameterWrapper(\n",
       "                (view_shape_impl): OverTensorView()\n",
       "              )\n",
       "              (stats): _Stats(\n",
       "                (stats_impl): AbsMax()\n",
       "              )\n",
       "            )\n",
       "            (stats_scaling_impl): _StatsScaling(\n",
       "              (affine_rescaling): Identity()\n",
       "              (restrict_clamp_scaling): _RestrictClampValue(\n",
       "                (clamp_min_ste): ScalarClampMinSte()\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (restrict_scaling_pre): Identity()\n",
       "              (restrict_scaling_impl): FloatRestrictValue()\n",
       "            )\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (bias_quant): BiasQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "    )\n",
       "    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "    (12): QuantReLU(\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (act_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "          (activation_impl): ReLU()\n",
       "          (tensor_quant): RescalingIntQuant(\n",
       "            (int_quant): IntQuant(\n",
       "              (float_to_int_impl): RoundSte()\n",
       "              (tensor_clamp_impl): TensorClamp()\n",
       "              (delay_wrapper): DelayWrapper(\n",
       "                (delay_impl): _NoDelay()\n",
       "              )\n",
       "              (input_view_impl): Identity()\n",
       "            )\n",
       "            (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
       "              (stats_input_view_shape_impl): OverTensorView()\n",
       "              (stats): _Stats(\n",
       "                (stats_impl): AbsPercentile()\n",
       "              )\n",
       "              (restrict_scaling_impl): FloatRestrictValue()\n",
       "              (restrict_scaling): _RestrictValue(\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (clamp_scaling): _ClampValue(\n",
       "                (clamp_min_ste): ScalarClampMinSte()\n",
       "              )\n",
       "              (restrict_inplace_preprocess): Identity()\n",
       "              (restrict_preprocess): Identity()\n",
       "            )\n",
       "            (int_scaling_impl): IntScaling()\n",
       "            (zero_point_impl): ZeroZeroPoint(\n",
       "              (zero_point): StatelessBuffer()\n",
       "            )\n",
       "            (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "              (bit_width): StatelessBuffer()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): QuantLinear(\n",
       "      in_features=64, out_features=4, bias=True\n",
       "      (input_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (output_quant): ActQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "      (weight_quant): WeightQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "        (tensor_quant): RescalingIntQuant(\n",
       "          (int_quant): IntQuant(\n",
       "            (float_to_int_impl): RoundSte()\n",
       "            (tensor_clamp_impl): TensorClampSte()\n",
       "            (delay_wrapper): DelayWrapper(\n",
       "              (delay_impl): _NoDelay()\n",
       "            )\n",
       "            (input_view_impl): Identity()\n",
       "          )\n",
       "          (scaling_impl): StatsFromParameterScaling(\n",
       "            (parameter_list_stats): _ParameterListStats(\n",
       "              (first_tracked_param): _ViewParameterWrapper(\n",
       "                (view_shape_impl): OverTensorView()\n",
       "              )\n",
       "              (stats): _Stats(\n",
       "                (stats_impl): AbsMax()\n",
       "              )\n",
       "            )\n",
       "            (stats_scaling_impl): _StatsScaling(\n",
       "              (affine_rescaling): Identity()\n",
       "              (restrict_clamp_scaling): _RestrictClampValue(\n",
       "                (clamp_min_ste): ScalarClampMinSte()\n",
       "                (restrict_value_impl): FloatRestrictValue()\n",
       "              )\n",
       "              (restrict_scaling_pre): Identity()\n",
       "              (restrict_scaling_impl): FloatRestrictValue()\n",
       "            )\n",
       "          )\n",
       "          (int_scaling_impl): IntScaling()\n",
       "          (zero_point_impl): ZeroZeroPoint(\n",
       "            (zero_point): StatelessBuffer()\n",
       "          )\n",
       "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (bias_quant): BiasQuantProxyFromInjector(\n",
       "        (_zero_hw_sentinel): StatelessBuffer()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qnt_output): QuantIdentity(\n",
       "    (input_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): ClampedBinaryQuant(\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (clamp_min_ste): ScalarClampMinSte()\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "            )\n",
       "            (restrict_init_module): Identity()\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (bit_width): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "          (zero_point): StatelessBuffer()\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "          (tensor_clamp_impl): TensorClamp()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from brevitas.nn import QuantIdentity\n",
    "\n",
    "\n",
    "class MLPForExport(nn.Module):\n",
    "    def __init__(self, my_pretrained_model, dim=128):\n",
    "        super(MLPForExport, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.qnt_output = QuantIdentity(\n",
    "            quant_type='binary', \n",
    "            scaling_impl_type='const',\n",
    "            bit_width=1, min_val=-1.0, max_val=1.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # assume x contains bipolar {-1,1} elems\n",
    "        # shift from {-1,1} -> {0,1} since that is the\n",
    "        # input range for the trained network\n",
    "        out_original = self.pretrained(x)\n",
    "        out_final = self.qnt_output(out_original)   # output as {-1,1}     \n",
    "        return out_final\n",
    "\n",
    "model_for_export = MLPForExport(model)\n",
    "model_for_export.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to QONNX and Conversion to FINN-ONNX <a id=\"export_qonnx\" ></a>\n",
    "\n",
    "\n",
    "[ONNX](https://onnx.ai/) is an open format built to represent machine learning models, and the FINN compiler expects an ONNX model as input. We'll now export our network into ONNX to be imported and used in FINN for the next notebooks. Note that the particular ONNX representation used for FINN differs from standard ONNX, you can read more about this [here](https://finn.readthedocs.io/en/latest/internals.html#intermediate-representation-finn-onnx).\n",
    "\n",
    "You can see below how we export a trained network in Brevitas into a FINN-compatible ONNX representation (QONNX). QONNX is the format we can export from Brevitas, to feed it into the FINN compiler, we will need to make a conversion to the FINN-ONNX format which is the intermediate representation the compiler works on. The conversion of the FINN-ONNX format is a FINN compiler transformation and to be able to apply it to our model, we will need to wrap it into [ModelWrapper](https://finn.readthedocs.io/en/latest/internals.html#modelwrapper). This is a wrapper around the ONNX model which provides several helper functions to make it easier to work with the model. Then we can call the conversion function to obtain the model in FINN-ONNX format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n",
      "Model saved to plutoMLP.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dspedia/.local/lib/python3.10/site-packages/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 17. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "ready_model_filename = \"plutoMLP.onnx\"\n",
    "input_shape = (1, 2048)\n",
    "\n",
    "#model_for_export = model\n",
    "\n",
    "\n",
    "# create a QuantTensor instance to mark input as bipolar during export\n",
    "input_a = np.random.randint(1, size=input_shape).astype(np.float32)\n",
    "scale = 1.0\n",
    "input_t = torch.from_numpy(input_a * scale)\n",
    "print(input_t.shape)\n",
    "\n",
    "#Move to CPU before export\n",
    "model_for_export.cpu()\n",
    "\n",
    "# Export to ONNX\n",
    "export_qonnx(\n",
    "    model_for_export, export_path=ready_model_filename, input_t=input_t\n",
    ")\n",
    "\n",
    "# clean-up\n",
    "qonnx_cleanup(ready_model_filename, out_file=ready_model_filename)\n",
    "\n",
    "# ModelWrapper\n",
    "outmodel = ModelWrapper(ready_model_filename)\n",
    "# Setting the input datatype explicitly because it doesn't get derived from the export function\n",
    "outmodel.set_tensor_datatype(outmodel.graph.input[0].name, DataType[\"FLOAT32\"])\n",
    "outmodel = outmodel.transform(ConvertQONNXtoFINN())\n",
    "outmodel.save(ready_model_filename)\n",
    "\n",
    "print(\"Model saved to %s\" % ready_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Exported ONNX in Netron\n",
    "\n",
    "Let's examine the exported ONNX model with [Netron](https://github.com/lutzroeder/netron), which is a visualizer for neural networks and allows interactive investigation of network properties. For example, you can click on the individual nodes and view the properties. Particular things of note:\n",
    "\n",
    "* The input tensor \"0\" is annotated with `quantization: finn_datatype: BIPOLAR`\n",
    "* The input preprocessing (x + 1) / 2 is exported as part of the network (initial `Add` and `Div` layers)\n",
    "* Brevitas `QuantLinear` layers are exported to ONNX as `MatMul`. We've exported the padded version; shape of the first MatMul node's weight parameter is 600x64\n",
    "* The weight parameters (second inputs) for MatMul nodes are annotated with `quantization: finn_datatype: INT2`\n",
    "* The quantized activations are exported as `MultiThreshold` nodes with `domain=qonnx.custom_op.general`\n",
    "* There's a final `MultiThreshold` node with threshold=0 to produce the final bipolar output (this is the `qnt_output` from `CybSecMLPForExport`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'plutoMLP.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x749e90066590>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(ready_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's it! <a id=\"thats_it\" ></a>\n",
    "You created, trained and tested a quantized MLP that is ready to be loaded into FINN, congratulations! You can now proceed to the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
